# Sources

- [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)
- [Energy-Latency Attacks to On-Device Neural Networks via Sponge Poisoning](https://arxiv.org/abs/2305.03888)
- [Hugging Face Docs: Pickle Scanning](https://huggingface.co/docs/hub/en/security-pickle)
- [MetaPoison: Practical General-purpose Clean-label Data Poisoning](https://arxiv.org/abs/2004.00225)
- [Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks](https://arxiv.org/abs/1804.00792)
- [Scalable Extraction of Training Data from (Production) Language Models](https://arxiv.org/abs/2311.17035)
- [Sigstore: Model Transparency](https://github.com/sigstore/model-transparency?tab=readme-ov-file)
